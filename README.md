# ğŸš€ **DeepSeek ç§äºº Chatbot 1.0ï¼šä¸€ä½“åŒ–é›†æˆ GraphRAG & èŠå¤©è®°å½• & ç½‘ç»œæœç´¢**
**(100% å…è´¹ï¼Œç§äººï¼Œæ— éœ€è”ç½‘ï¼Œç§æœ‰åŒ–éƒ¨ç½²)**  

## ä»‹ç»

ğŸ”¥ **DeepSeek + NOMIC + FAISS + Neural Reranking + HyDE + GraphRAG + Chat Memory + searxng web search  = ç»ˆæ RAG æŠ€æœ¯æ ˆ!**  

æœ¬èŠå¤©æœºå™¨äººé€šè¿‡æœ€å°åŒ–é›†æˆ **DeepSeek-8B**ï¼Œ**qwen2-1.5b æ–‡æœ¬åµŒå…¥æ¨¡å‹**ï¼Œ**BAAI/bge é‡æ’æ¨¡å‹(äº¤å‰ç¼–ç å™¨)**ï¼Œ**GraphRAG**ï¼Œå’Œ **èŠå¤©å†å²**  æ¥æ”¯æŒä» PDFsï¼ŒDOCXï¼Œand TXT æ–‡ä»¶å¿«é€Ÿã€ç²¾ç¡®ã€å¯è§£é‡Šçš„æ£€ç´¢å¢å¼º LLM æœåŠ¡ã€‚åªæœ‰ä¸€ä¸ª ``app.py`` æ–‡ä»¶ï¼Œçµæ´»æ˜“æ‹“å±•ï¼Œé€‚åˆä½œä¸ºä½ çš„ LLM chatbot å­¦ä¹ èµ·ç‚¹æˆ–å®šåˆ¶ä¸ªæ€§åŒ–æœºå™¨äººã€‚ 

å¦‚æœä½ åŒå€¦äº† Dify ä»¥åŠå„ç§ xxx studio çš„ all-in-one çš„åºæ‚å’Œé…ç½®ç¹çï¼Œåªéœ€è¦çŸ¥è¯†åº“ã€åœ¨çº¿æœç´¢ã€å¯¹è¯å†å²ç­‰åŸºæœ¬åŠŸèƒ½ï¼Œç§æœ‰åŒ–éƒ¨ç½²åœ¨è‡ªå·±çš„ Home Lab é‡Œï¼Œéšæ—¶å¯è°ƒæ•´æ§åˆ¶æ¯ä¸ªç»†èŠ‚ï¼Œé‚£è¿™ä¸ªé¡¹ç›®å°±æ˜¯ä¸ºä½ å‡†å¤‡çš„ã€‚

---

# **å®‰è£… & è®¾ç½®**

ä½ å¯ä»¥é€‰æ‹©ä»¥ä¸‹ä¸¤ç§å®‰è£…æ–¹å¼ä¹‹ä¸€æ¥éƒ¨ç½² **DeepSeek Private Chatbot**ï¼š

1ã€‚**ä¼ ç»Ÿ (Python/venv) å®‰è£…**  
2ã€‚**Docker å®¹å™¨åŒ–å®‰è£…** (éå¸¸ç†æƒ³çš„å®¹å™¨åŒ–éƒ¨ç½²æ–¹å¼)

---

## **1ï¸âƒ£ ä¼ ç»Ÿ (Python/venv) å®‰è£…**

### **æ­¥éª¤ A: Clone the Repository & Install Dependencies**
```
git clone https://github.com/faywong/DeepSeek-Private-Chatbot.git
cd DeepSeek-Private-Chatbot

# Create a virtual environment
python -m venv venv

# Activate your environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Upgrade pip (optionalï¼Œbut recommended)
pip install --upgrade pip

# Install project dependencies
pip install -r requirements.txt
```

### **æ­¥éª¤ B: ä¸‹è½½ & è®¾ç½® Ollama**
1ã€‚**ä¸‹è½½ Ollama** â†’ [https://ollama.com/](https://ollama.com/)  
2ã€‚**æ‹‰å–æ‰€éœ€æ¨¡å‹**:
   ```
   ollama pull deepseek-r1:8b
   ollama pull rjmalagon/gte-qwen2-1.5b-instruct-embed-f16
   ```
   *æ³¨æ„: ä½ å¯ä»¥é€šè¿‡ç¼–è¾‘ `MODEL` æˆ– `EMBEDDINGS_MODEL` ç¯å¢ƒå˜é‡ï¼ˆæˆ– `.env` æ–‡ä»¶ï¼‰æ¥ä½¿ç”¨å…¶ä»–çš„æ¨¡å‹*   

### **æ­¥éª¤ C: è¿è¡Œå¯¹è¯æœºå™¨äºº**
1ã€‚å¯åŠ¨ **Ollama** æœåŠ¡:
   ```
   ollama serve
   ```
2ã€‚å¯åŠ¨ app.pyï¼ˆStreamlit åº”ç”¨ï¼‰:
   ```
   streamlit run app.py
   ```
3ã€‚æ‰“å¼€æµè§ˆå™¨è®¿é—® **[http://localhost:8501](http://localhost:8501)** æ¥è®¿é—® chatbot UI.

---

## **2ï¸âƒ£ Docker å®¹å™¨åŒ–å®‰è£…**

### **A) å•å®¹å™¨å®ä¾‹æ–¹å¼ (Ollama è¿è¡Œåœ¨ä½ çš„å®¿ä¸»æœº)**

å¦‚æœ **Ollama** å·²ç»è¿è¡Œåœ¨ä½ çš„å®¿ä¸»æœºå¹¶ä¾¦å¬åœ¨ `localhost:11434`ï¼Œé‚£ä¹ˆå¯ä»¥ç›´æ¥:

1ã€‚**æ„å»º & è¿è¡Œ**:
   ```
   docker-compose build
   docker-compose up
   ```
2ã€‚å¯¹è¯æœºå™¨äººå°±è¿è¡Œåœ¨ **[http://localhost:8501](http://localhost:8501)**ã€‚

### **B) ä¸¤å®¹å™¨å®ä¾‹ç¼–æ’æ–¹å¼ (Ollama è¿è¡Œåœ¨ docker é‡Œ)**

å¦‚æœä½ å–œæ¬¢ **ä¸€åˆ‡** åœ¨ Dockerï¼Œé‚£ä¹ˆå¯ä»¥é€šè¿‡ `docker compose` æ¥ç¼–æ’ä¸‹:
```
version: "3.8"

services:
  ollama:
    image: ghcr.io/jmorganca/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"

  searxng:
    image: docker.io/searxng/searxng:latest
    container_name: searxng
    ports:
      - "4000:8080"
    volumes:
      - ./searxng:/etc/searxng
    restart: unless-stopped

  deepgraph-rag-service:
    container_name: deepgraph-rag-service
    build: .
    ports:
      - "8501:8501"
    environment:
      - OLLAMA_API_URL=http://ollama:11434
      - MODEL=deepseek-r1:8b
      - EMBEDDINGS_MODEL=rjmalagon/gte-qwen2-1.5b-instruct-embed-f16:latest
      - CROSS_ENCODER_MODEL=BAAI/bge-reranker-large
    depends_on:
      - ollama
      - searxng

```

ç„¶åæ„å»ºå’Œå¯åŠ¨:
```
docker-compose build
docker-compose up
```

**Ollama** å’ŒèŠå¤©æœºå™¨äººã€æœç´¢æœåŠ¡ `searxng` éƒ½åœ¨å®¹å™¨ä¸­è¿è¡Œã€‚åŒæ ·åœ¨ url **[http://localhost:8501](http://localhost:8501)** ä¸Šæ¥è®¿é—®èŠå¤©æœºå™¨äºº.

æ³¨æ„ï¼šä¸ç®¡ä½ é€‰æ‹©ä»¥ä¸Šå“ªç§å®‰è£…æ–¹å¼ï¼Œä½ éƒ½å¯ä»¥é€šè¿‡æ›´æ”¹ `OLLAMA_API_URL` ç¯å¢ƒå˜é‡ï¼ˆé»˜è®¤å€¼ä¸ºï¼šhttp://localhost:11434ï¼‰æ¥æŒ‡å‘ä½ å…·ä½“ç¯å¢ƒä¸‹çš„ ollama æœåŠ¡åœ°å€ã€‚

å¿«æ·å§¿åŠ¿ï¼šå¸¦æœ‰ hf_cache çš„ç°æˆ [docker é•œåƒ](https://hub.docker.com/repository/docker/faywong8888/deepseek-private-chatbot/)
---

# **è¿™ä¸ªèŠå¤©æœºå™¨äººå¦‚ä½•å·¥ä½œ**

1. **Upload Documents**: Add PDFsï¼ŒDOCXï¼Œor TXT files via the sidebarã€‚ 
2. **Hybrid Retrieval**: Combines **BM25** and **FAISS** to fetch the most relevant text chunksã€‚ 
3. **GraphRAG Processing**: Builds a **Knowledge Graph** from your documents to understand relationships and contextã€‚
4. **Web Search**: Do a web search with [searxng](https://github.com/searxng/searxng)ï¼Œand append it the context as data Source for referã€‚ 
5. **Neural Reranking**: Uses a **Cross-Encoder** model for reordering the retrieved chunks by relevanceã€‚ 
6. **Query Expansion (HyDE)**: Generates hypothetical answers to **expand** your query for better recallã€‚ 
7. **Chat Memory History Integration**: Maintains context by referencing previous user messagesã€‚ 
8. **DeepSeek-8B Generation**: Produces the final answer based on top-ranked chunks.

---

## ğŸ“Œ è´¡çŒ® 

- **å…‹éš†** è¿™ä¸ªä»“åº“ï¼Œæäº¤ **pull requests**ï¼Œæˆ–åˆ›å»º **issues**ã€‚ 
---

### ğŸ”— åˆ†äº«æƒ³æ³•

æœ‰åé¦ˆæˆ–å»ºè®®ï¼Œå¯ä»¥é€šè¿‡ [**V2EX**](https://www.v2ex.com/member/faywong8888) è”ç³»æˆ‘! ğŸš€ğŸ’¡

---